{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4: Interpretable Machine Learning for Data Science\n",
    "\n",
    "**Problem**: You have been mandated by a large wine-making company in Valais to discover the key chemical factors that determine the quality of wine and build an interpretable model that will help their cellar masters make decisions daily.\n",
    "\n",
    "## Settings things up (15')\n",
    "\n",
    "This week will require quite a lot of autonomy on your part, but we will guide you with this high-level notebook. First, take the following steps:\n",
    "\n",
    "- Install [Poetry](https://python-poetry.org). \n",
    "- Then use Poetry to create a virtual environment:\n",
    "\n",
    "  ```sh\n",
    "  poetry install\n",
    "  ```\n",
    "\n",
    "- Then restart VS Code and add the kernel that corresponds to the environment created by Poetry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's set up [black](https://github.com/psf/black), which is a highly encouraged best-practice for all your Python projects. That way, you never have to worry and debate about code formatting anymore. By using it, you agree to cede control over minutiae of hand-formatting. In return, Black gives you speed, determinism, and freedom from `pycodestyle` nagging about formatting. You will save time and mental energy for more important matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the libraries you will most likely need and use during this week:\n",
    "\n",
    "- `numpy` for basic scientific computing and `scipy` for statistical testing.\n",
    "- `pandas` or `polars` for dataset manipulation. Polars is highly recommended, because it is [awesome](https://github.com/ddotta/awesome-polars). Instructions below will refer to the Polars API.\n",
    "- `seaborn` for statistical data visualization, but `matplotlib` is always needed anyway. Use both!\n",
    "- `shap` will be used for [interpretability](https://shap.readthedocs.io/en/stable/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html).\n",
    "- `sklearn` and `xgboost` will be used for training models. You may import them later when you need them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the data (15')\n",
    "\n",
    "Here we have a very nice package that can do everything for us (aka `ucimlrepo`). Let's use it!\n",
    "\n",
    "Take a look at [the website](https://archive.ics.uci.edu/dataset/186/wine+quality) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check that the data have the correct shape to ensure they have been loaded as expected.\n",
    "\n",
    "Calculate how many samples and features we have in total, how many are red or white wines, how many are good or bad wines, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration (1h30)\n",
    "\n",
    "We now will inspect the features one-by-one, and try to understand their dynamics, especially between white and red wines.\n",
    "\n",
    "- Use `Dataframe.describe` to display statistics on each feature. Do the same for red wines only, and white wines only. Do you notice any clear difference?\n",
    "- Compute the effect size by computing the [strictly standardized mean difference](https://en.wikipedia.org/wiki/Strictly_standardized_mean_difference) (SSMD) between the red and white wines for each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's go a bit deeper into the same analysis, using more visual tools:\n",
    "\n",
    "- For every feature, plot boxplots, violinplots or histograms for red and white wines. What can you infer? **If you feel a bit more adventurous**, plot the Cumulative Distribution Function (CDF) of the feature for white and red wines, and compute the [Kullback-Leibler divergence](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html) (or entropy) between them. Explain why this might be useful.\n",
    "- Plot the correlation matrix of all features as heatmaps, one for red and one for white wines. How do they differ? What can you infer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration using Unsupervised Learning (3h)\n",
    "\n",
    "We first explore the data in an unsupervised fashion. Start by creating a heatmap of the average feature value for red and white wines. Can you spot an easy way to differentiate between reds and whites?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PCA to reduce the dimensionality\n",
    "\n",
    "Use PCA to reduce the dimensionality of data. Do not forget that it requires data normalization (centering on the mean and scaling to unit variance). Plot the whole dataset onto the two principal components and color it by wine color. What does it tell you?\n",
    "\n",
    "Project the unit vectors that correspond to each vector onto the principal components, using the same transformation. What does it tell you about the relative feature importance? Does it match the observations you made previously?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster the data in 2-dimensional space\n",
    "\n",
    "Use k-means to cluster the data into 2 clusters and plot the same view as before, but with a coloring that corresponds to the cluster memberships.\n",
    "\n",
    "Assuming that the cluster assignments are predictions of a model, what is the performance you can achieve in terms of mutual information score, accuracy, and f1 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to train a **supervised** linear classification model using `sklearn`, and compare the results with the approach using clustering.\n",
    "\n",
    "- Set up a train/test dataset using `sklearn.model_selection.train_test_split`.\n",
    "- Use `GridSearchCV` to perform a cross-validation of the model's regularization `C`.\n",
    "- Compare the test and train performance at the end. Does the model suffer from any overfitting? \n",
    "- Analyze the test performance specifically. What can you conclude about this general problem of recognizing white vs red wines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic model interpretability: inspecting the model\n",
    "\n",
    "As a first step towards intepretability of the model predictions, let's take a look at the coefficients of the model. What is the most important feature from this perspective? How do you interpret positive or negative coefficients?\n",
    "\n",
    "Is it compatible with what you have seen so far? Do you have an explanation why that might be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing features to test their importance\n",
    "\n",
    "- What happens if you re-train a model, but remove the most important feature in the list?\n",
    "- What happens if you re-train the model with a `l1` penalty and you use more regularization? \n",
    "- Interpret the results you obtained above from the perspective of the business problem. What does it tell you about the key differences between a red and white wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Shapley values\n",
    "\n",
    "Now, use SHAP to explore how the model perceives a 'red' and 'white' wine.\n",
    "\n",
    "- Use a `beeswarm` plot to analyze the influence of each feature on the model's output.\n",
    "- What does the plot tell us about what makes a white wine 'white' and a red wine 'red'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now use Partial Dependence Plots to see how the expected model output varies with the variation of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now use a waterfall diagram on a specific red and white wine and see how the model has made this specific prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, let's take an example where the model has made an incorrect prediction, and see how it made this prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good vs Bad classification (3h)\n",
    "\n",
    "We are going to work on a binary classification problem, where all wines with a quality higher than 6 are considered as \"good\" and other are considered as \"bad\".  \n",
    "\n",
    "- Prepare a dataset with a new column `binary_quality` that corresponds to the above definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One question that we might ask right away is:\n",
    "\n",
    "- Is there any correlation of the quality and the color of the wine? \n",
    "\n",
    "Ideally, there should be almost none. Why could it be a problem otherwise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it turns out that there are significantly more bad red wines than bad white wines or vice versa, what are the implications for your analysis?\n",
    "\n",
    "- Plot a heatmap of the mean feature value for bad and good wines, like we did before for red and white wines.\n",
    "- Plot two heatmaps, one for red and white wines. How do they differ? What kind of issue can it cause?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a lot more difficult now to tell apart good from bad wines. Let's turn to a more complex model, which is a [Gradient Boosting](https://en.wikipedia.org/wiki/Gradient_boosting) [Trees](https://xgboost.readthedocs.io/en/stable/tutorials/model.html). For the sake of interpretability, design your notebook so that you can easily filter on only white and red wines and perform again the entire procedure.\n",
    "\n",
    "Let's first train a XGBClassifier model to distinguish between good and bad wines. Make sure to use the same best-practices (train/test split, cross-validation) as we did before. Note that the regularization of the GBTs is a lot more complex than for Logistic Regression. Test the following parameters:\n",
    "\n",
    "  ```py\n",
    "  param_grid = {\n",
    "    \"max_depth\": [3, 4, 5],  # Focus on shallow trees to reduce complexity\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],  # Slower learning rates\n",
    "    \"n_estimators\": [50, 100],  # More trees but keep it reasonable\n",
    "    \"min_child_weight\": [1, 3],  # Regularization to control split thresholds\n",
    "    \"subsample\": [0.7, 0.9],  # Sampling rate for boosting\n",
    "    \"colsample_bytree\": [0.7, 1.0],  # Sampling rate for columns\n",
    "    \"gamma\": [0, 0.1],  # Regularization to penalize complex trees\n",
    "  }\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyze the results (test and train), validate whether there is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretability with SHAP (2h)\n",
    "\n",
    "- Plot the feature importance (gain and cover) from the XGBoost model. What can you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use SHAP's `TreeExplainer` to compute feature importance (Shapley values). Do you see any difference with XGBoost's feature importances?\n",
    "- Produce different plots to analyze Shapley values: \n",
    "  - A bar plot that summarizes the mean absolute value of each feature.\n",
    "  - A beeswarm plot that shows the shapley value for every sample and every feature.\n",
    "  - A [heatmap plot](https://shap.readthedocs.io/en/stable/example_notebooks/api_examples/plots/heatmap.html#heatmap-plot) that indicates how different feature patterns influence the model's output.\n",
    "- Based on the above results, what makes a wine 'good' or 'bad'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now use Partial Dependence Plots to see how the expected model output varies with the variation of each feature.\n",
    "- How does that modify your perspective on what makes a good or bad wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Search for literature or resources that provide indications of the chemical structure of good or poor wines. Do your findings match these resources? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze a few bad wines, and try to see how to make them better\n",
    "\n",
    "Pick some of the worst wines, and try to see what make them so bad. Check out [`shap.plots.heatmap`](https://shap.readthedocs.io/en/stable/example_notebooks/api_examples/plots/heatmap.html#heatmap-plot) for some visual tool to do this.\n",
    "\n",
    "How would you go about improving them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrap-up and conclusion\n",
    "\n",
    "As wrap-up, explain what are your key findings, and make 3 recommendations to the wine maker on how to improve the wines for next year. How confident are you that making these changes will lead to better wines? Explain in simple terms to the winemaker the limitations of your approach in terms of capturing causality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
